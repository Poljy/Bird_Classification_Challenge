{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9X7f64rpr6wz"
   },
   "source": [
    "# A3 JACOB Paul\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNufrmduAZrw"
   },
   "source": [
    "## Download and upzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpTI8T6qAboF"
   },
   "outputs": [],
   "source": [
    "!wget -nc https://www.di.ens.fr/willow/teaching/recvis18orig/assignment3/bird_dataset.zip\n",
    "!unzip -q bird_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "piFGe9UBwkp5"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xPko-CLw3iw"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import argparse\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import PIL\n",
    "import PIL.Image as Image\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHX4qbbgINKI"
   },
   "source": [
    "## Data cropping using R-CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMIYaIlmIeY2"
   },
   "source": [
    "Loading R-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8-wwvIDUIPaA"
   },
   "outputs": [],
   "source": [
    "rcnn = models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    rcnn.cuda()\n",
    "else:\n",
    "    print('Using CPU')\n",
    "\n",
    "rcnn.eval()\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "coxxoxcuKB0I"
   },
   "source": [
    "Generate cropped dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IDQQHo14Ig2p"
   },
   "outputs": [],
   "source": [
    "##Parameters\n",
    "\n",
    "data_dir = 'bird_dataset'\n",
    "margins_train = [0.1,0.2,0.5]\n",
    "margins_val = [0.2]\n",
    "margins_test = [0.2]\n",
    "check_all_labels = True\n",
    "\n",
    "##Core loop\n",
    "\n",
    "!rm -rf cropped_data/\n",
    "\n",
    "#Stores the birds which have not been cropped\n",
    "outliers = []\n",
    "\n",
    "def pil_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "  \n",
    "\n",
    "for dir in os.listdir(data_dir) :\n",
    "  print()\n",
    "  print(\"Retrieving birds in\", dir)\n",
    "  dataset = os.path.join(data_dir,dir)\n",
    "  \n",
    "  if dir == \"train_images\":\n",
    "    margins = margins_train\n",
    "  elif dir == \"val_images\":\n",
    "    margins = margins_val\n",
    "  elif dir == \"test_images\":\n",
    "    margins = margins_test\n",
    "    assert len(margins) == 1\n",
    "    \n",
    "  for bird_class in os.listdir(dataset):\n",
    "\n",
    "    print(\"Working on class\", bird_class)\n",
    "\n",
    "    bird_class_data = os.path.join(dataset,bird_class)\n",
    "    if not os.path.isdir(os.path.join(\"cropped_data\",bird_class_data)):\n",
    "      os.makedirs(os.path.join(\"cropped_data\",bird_class_data))\n",
    "\n",
    "    for bird in os.listdir(bird_class_data):\n",
    "      \n",
    "      #Retrieve bird image, load it and apply Mask R-CNN\n",
    "      bird_path = os.path.join(bird_class_data,bird)\n",
    "      data = transforms.ToTensor()(pil_loader(bird_path))\n",
    "      data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "      data_c = data.cuda()\n",
    "      outputs = rcnn(data_c)\n",
    "\n",
    "      #Look for a bird in the image (in the whole list if \"check_all_labels\")\n",
    "      labels = outputs[0]['labels']\n",
    "      good_label = 0\n",
    "      if check_all_labels:\n",
    "        for i,lab in enumerate(labels):\n",
    "          if lab == 16:\n",
    "            good_label = i\n",
    "            break\n",
    "\n",
    "      #Crop the image if a bird has been retrieved\n",
    "      if len(labels) > 0 and labels[good_label] == 16 :\n",
    "\n",
    "        x1,y1,x2,y2 = outputs[0]['boxes'][good_label]\n",
    "\n",
    "        y = y2-y1\n",
    "        x = x2-x1\n",
    "\n",
    "        for margin in margins:\n",
    "\n",
    "          x1 = max(int(x1-margin*x),0)\n",
    "          x2 = min(int(x2+margin*x),len(data[0,0,0,:])-1)\n",
    "          y1 = max(int(y1-margin*y),0)\n",
    "          y2 = min(int(y2+margin*y),len(data[0,0,:,0])-1)\n",
    "\n",
    "          cropped_data = data[:,:,y1:y2,x1:x2]\n",
    "          cropped_data = cropped_data[0].transpose(0,2).transpose(0,1).numpy()\n",
    "      \n",
    "          if dir == \"test_images\":\n",
    "            plt.imsave(os.path.join(\"cropped_data\",bird_path),cropped_data)\n",
    "          else:\n",
    "            os.path.join(bird_class_data,bird)\n",
    "            plt.imsave(os.path.join(\"cropped_data\",os.path.join(bird_class_data,str(int(100*margin))+bird)),cropped_data)\n",
    "\n",
    "      #Otherwise saves the image as the original\n",
    "      else:\n",
    "        print(\"WARNING: Bird has not been cropped in this image:\", bird_path)\n",
    "        outliers.append(bird_path)\n",
    "        cropped_data = data[:,:,:,:]\n",
    "        cropped_data = cropped_data[0].transpose(0,2).transpose(0,1).numpy()\n",
    "        plt.imsave(os.path.join(\"cropped_data\",bird_path),cropped_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uNG3shkKGjo"
   },
   "source": [
    "Check that the transformed test dataset has been adequately processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZXCych3yKMfP"
   },
   "outputs": [],
   "source": [
    "for dir in os.listdir(data_dir) :\n",
    "  dataset = os.path.join(data_dir,dir)\n",
    "  if dataset == \"test_images\":\n",
    "    for bird_class in os.listdir(dataset):\n",
    "      bird_class_data = os.path.join(dataset,bird_class)\n",
    "      for bird in os.listdir(bird_class_data):\n",
    "        if not os.path.isfile(os.path.join(\"cropped_data\",bird_path)) :\n",
    "          raise ValueError(\"One image has not been processed !\")\n",
    "\n",
    "print(\"The transformed test set looks good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qewxT-IRhIDw"
   },
   "source": [
    "(Optional) Take a look at the list of outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQGZfHSwhHkN"
   },
   "outputs": [],
   "source": [
    "look_at_outliers = True\n",
    "\n",
    "if look_at_outliers:\n",
    "  for outlier_path in outliers:\n",
    "\n",
    "    img = pil_loader(outlier_path)\n",
    "\n",
    "    data = transforms.ToTensor()(img)\n",
    "    data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "    data_c = data.cuda()\n",
    "    outputs = rcnn(data_c)\n",
    "    labels = outputs[0]['labels'].cpu().numpy()\n",
    "\n",
    "    print(\"Path:\",outlier_path)\n",
    "    print(\"Labels:\",labels)\n",
    "    print(\"Original image:\")\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    good_label = -1\n",
    "    for i,lab in enumerate(labels):\n",
    "      if lab == 16:\n",
    "        good_label = i\n",
    "        break\n",
    "\n",
    "    if good_label > -1 :\n",
    "\n",
    "      x1,y1,x2,y2 = outputs[0]['boxes'][good_label]\n",
    "      y = y2-y1\n",
    "      x = x2-x1\n",
    "        \n",
    "      x1 = max(int(x1-0.2*x),0)\n",
    "      x2 = min(int(x2+0.2*x),len(data[0,0,0,:])-1)\n",
    "      y1 = max(int(y1-0.2*y),0)\n",
    "      y2 = min(int(y2+0.2*y),len(data[0,0,:,0])-1)\n",
    "      \n",
    "      cropped_data = data[:,:,y1:y2,x1:x2]\n",
    "      cropped_data = cropped_data[0].transpose(0,2).transpose(0,1).numpy()\n",
    "      print(\"First bird found:\",labels)\n",
    "      plt.imshow(cropped_data)\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jFbcOpm-KQVT"
   },
   "source": [
    "(Optional) Zip cropped data to save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h8jQ9nKhKY_u"
   },
   "outputs": [],
   "source": [
    "!zip -q -r /content/cropped_data.zip /content/cropped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4AJxm7cw9_f"
   },
   "source": [
    "## Data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0DAfOrBw6Rd"
   },
   "outputs": [],
   "source": [
    "img_size = (256,256)\n",
    "img_crop_size = (224,224)\n",
    "persp_distortion_scale=0.25\n",
    "rotation_range=(-10.0,10.0)\n",
    "random_crop_scale = (0.9, 1.0)\n",
    "hue_variation_scale = .02\n",
    "saturarion_variation_scale = .02\n",
    "\n",
    "data_transforms_train_cropped = transforms.Compose([\n",
    "                                            #transforms.RandomResizedCrop(img_crop_size, scale=random_crop_scale),\n",
    "                                            #transforms.ColorJitter(hue=hue_variation_scale, saturation=saturarion_variation_scale),\n",
    "                                            transforms.Resize(img_crop_size),\n",
    "                                            transforms.RandomHorizontalFlip(),\n",
    "                                            transforms.RandomPerspective(distortion_scale=persp_distortion_scale, p=0.5, interpolation=3),\n",
    "                                            transforms.RandomRotation(rotation_range, resample=False, expand=False, center=None, fill=None),\n",
    "                                            transforms.ToTensor(),\n",
    "                                            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                            ])\n",
    "\n",
    "\n",
    "data_transforms_val_test_cropped = transforms.Compose([\n",
    "                                          transforms.Resize(img_crop_size),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                          ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNvMcd63TJZl"
   },
   "source": [
    "## Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gt561a6aUrrP"
   },
   "outputs": [],
   "source": [
    "num_classes = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7OBNJ_BUaoj"
   },
   "outputs": [],
   "source": [
    "class TransferedResnet(nn.Module):\n",
    "  \n",
    "  def __init__(self,resnet=50, pretrained = True, layers_to_freeze=[]):\n",
    "    super(TransferedResnet,self).__init__()\n",
    "    if resnet==18:\n",
    "      self.resnet = models.resnet18(pretrained=pretrained)\n",
    "    elif resnet==34:\n",
    "      self.resnet = models.resnet34(pretrained=pretrained)\n",
    "    elif resnet==50:\n",
    "      self.resnet = models.resnet50(pretrained=pretrained)\n",
    "    elif resnet==101:\n",
    "      self.resnet = models.resnet101(pretrained=pretrained)\n",
    "    elif resnet==152:\n",
    "      self.resnet = models.resnet152(pretrained=pretrained)\n",
    "\n",
    "    for layer in layers_to_freeze:\n",
    "\n",
    "      if layer == 'conv1':\n",
    "        for param in self.resnet.conv1.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'bn1':\n",
    "        for param in self.resnet.bn1.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'layer1':\n",
    "        for param in self.resnet.layer1.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'layer2':\n",
    "        for param in self.resnet.layer2.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'layer3':\n",
    "        for param in self.resnet.layer3.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'layer4':\n",
    "        for param in self.resnet.layer4.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "    num_features = self.resnet.fc.in_features\n",
    "    self.resnet.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "  def forward(self, input):\n",
    "    return self.resnet(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t_0Skoh-3iVL"
   },
   "outputs": [],
   "source": [
    "class TransferedInception(nn.Module):\n",
    "  \n",
    "  def __init__(self, pretrained = True, frozen=True):\n",
    "    super(TransferedInception,self).__init__()\n",
    "\n",
    "    self.inception = models.inception_v3(pretrained=pretrained)\n",
    "    self.inception.aux_logits = False\n",
    "\n",
    "    if frozen:\n",
    "      for param in self.inception.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    num_features = self.inception.fc.in_features\n",
    "    self.inception.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "  def forward(self, input):\n",
    "    return self.inception(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b_Acq2zHGWl4"
   },
   "outputs": [],
   "source": [
    "class TransferedResneXt(nn.Module):\n",
    "  \n",
    "  def __init__(self,resneXt=50, pretrained = True, layers_to_freeze=[]):\n",
    "\n",
    "    super(TransferedResneXt,self).__init__()\n",
    "\n",
    "    if resneXt==50:\n",
    "      self.resnext = models.resnext50_32x4d(pretrained=pretrained)\n",
    "    elif resneXt==101:\n",
    "      self.resnext = models.resnext101_32x8d(pretrained=pretrained)\n",
    "\n",
    "    for layer in layers_to_freeze:\n",
    "\n",
    "      if layer == 'conv1':\n",
    "        for param in self.resnext.conv1.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'bn1':\n",
    "        for param in self.resnext.bn1.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'layer1':\n",
    "        for param in self.resnext.layer1.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'layer2':\n",
    "        for param in self.resnext.layer2.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'layer3':\n",
    "        for param in self.resnext.layer3.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'layer4':\n",
    "        for param in self.resnext.layer4.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "    num_features = self.resnext.fc.in_features\n",
    "    self.resnext.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "  def forward(self, input):\n",
    "    return self.resnext(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n894UkYYtlwJ"
   },
   "outputs": [],
   "source": [
    "class TransferedDensenet(nn.Module):\n",
    "  \n",
    "  def __init__(self,densenet=169, pretrained = True, layers_to_freeze=[]):\n",
    "\n",
    "    super(TransferedDensenet,self).__init__()\n",
    "\n",
    "    if densenet==121:\n",
    "      self.densenet = models.densenet121(pretrained=pretrained)\n",
    "    elif densenet==161:\n",
    "      self.densenet = models.densenet161(pretrained=pretrained)\n",
    "    elif densenet==169:\n",
    "      self.densenet = models.densenet169(pretrained=pretrained)\n",
    "    elif densenet==201:\n",
    "      self.densenet = models.densenet201(pretrained=pretrained)\n",
    "\n",
    "\n",
    "    for layer in layers_to_freeze:\n",
    "\n",
    "      if layer == 'conv0':\n",
    "        for param in self.densenet.features.conv0.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'norm0':\n",
    "        for param in self.densenet.features.norm0.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'denseblock1':\n",
    "        for param in self.densenet.features.denseblock1.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'transition1':\n",
    "        for param in self.densenet.features.transition1.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'denseblock2':\n",
    "        for param in self.densenet.features.denseblock2.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'transition2':\n",
    "        for param in self.densenet.features.transition2.parameters():\n",
    "          param.requires_grad = False\n",
    "      if layer == 'denseblock3':\n",
    "        for param in self.densenet.features.denseblock3.parameters():\n",
    "          param.requires_grad = False    \n",
    "      if layer == 'transition3':\n",
    "        for param in self.densenet.features.transition3.parameters():\n",
    "          param.requires_grad = False      \n",
    "      if layer == 'denseblock4':\n",
    "        for param in self.densenet.features.denseblock4.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "    num_features = self.densenet.classifier.in_features\n",
    "    self.densenet.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "  def forward(self, input):\n",
    "    return self.densenet(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xhDPrcuUShz"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rvnm-emLVrJY"
   },
   "source": [
    "Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b0oWM39TPc87"
   },
   "outputs": [],
   "source": [
    "data_dir = 'bird_dataset'\n",
    "batch_size = 128\n",
    "epochs = 2\n",
    "random_seed = 1\n",
    "log_interval = 10\n",
    "results_dir = 'results'\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "if not os.path.isdir(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TQ3TpmuzWQF0"
   },
   "source": [
    "Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FuZDJhYPWLss"
   },
   "outputs": [],
   "source": [
    "load_cropped_data = True\n",
    "\n",
    "if load_cropped_data:\n",
    "  train_loader = torch.utils.data.DataLoader(datasets.ImageFolder(os.path.join(\"cropped_data\", data_dir + '/train_images'),transform=data_transforms_train_cropped),batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "  val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(os.path.join(\"cropped_data\", data_dir + '/val_images'),transform=data_transforms_val_test_cropped),batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "else:\n",
    "  train_loader = torch.utils.data.DataLoader(datasets.ImageFolder(data_dir + '/train_images',transform=data_transforms_train),batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "  val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(data_dir + '/val_images',transform=data_transforms_val_test),batch_size=batch_size, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ckC97mudWhX6"
   },
   "source": [
    "Selecting model and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z327eZpQWlP8"
   },
   "outputs": [],
   "source": [
    "## Settings\n",
    "\n",
    "which_resnet = 152\n",
    "which_resnext = 101\n",
    "which_densenet = 201\n",
    "pretrained = True\n",
    "layers_to_freeze_resnet = ['conv1','bn1','layer1','layer2','layer3']\n",
    "layers_to_freeze_densenet = ['conv0','norm0','denseblock1','transition1','denseblock2','transition2','denseblock3','transition3']\n",
    "lr = 0.0001\n",
    "\n",
    "## Choose the model\n",
    "\n",
    "model = TransferedResnet(resnet=which_resnet,pretrained=pretrained,layers_to_freeze=layers_to_freeze_resnet)\n",
    "#model = TransferedResneXt(resneXt=which_resnext,pretrained=pretrained,layers_to_freeze=layers_to_freeze_resnet)\n",
    "#model = TransferedInception(pretrained=pretrained)\n",
    "#model = TransferedDensenet(densenet=which_densenet,pretrained=pretrained,layers_to_freeze=layers_to_freeze_densenet)\n",
    "\n",
    "## Choose the optimizer\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "#optimizer = optim.SGD(model.parameters(),lr=lr,momentum=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3, verbose=True, factor=0.5)\n",
    "\n",
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfRVs4fjXGSh"
   },
   "source": [
    "Training and validation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j90X0vTtXTqr"
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.data.item()))\n",
    "\n",
    "def validation():\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in val_loader:\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        output = model(data)\n",
    "        # sum up batch loss\n",
    "        criterion = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "        validation_loss += criterion(output, target).data.item()\n",
    "        # get the index of the max log-probability\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    validation_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(validation_loss)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)'.format(\n",
    "        validation_loss, correct, len(val_loader.dataset),\n",
    "        100. * correct / len(val_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U3fUKpgBXjbu"
   },
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvBI0oA7XiNn"
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch)\n",
    "    validation()\n",
    "    model_file = results_dir + '/model_' + str(epoch) + '.pth'\n",
    "    torch.save(model.state_dict(), model_file)\n",
    "    print('Saved model to ' + model_file + '. You can run `python evaluate.py --model ' + model_file + '` to generate the Kaggle formatted csv file\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a9JfDsS5UWMk"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "py_jiLJZX7uw"
   },
   "source": [
    "Evaluation settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kNVeHQ71PXNA"
   },
   "outputs": [],
   "source": [
    "model_path = 'results/model_2.pth'\n",
    "outfile = 'results/kaggle_resnet152_batch_128_frozen_layers_crops_02_05_08_2.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n21YKaQyYZun"
   },
   "source": [
    "Load model and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mp1ZAzxnQ0Rg"
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(model_path)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval()\n",
    "if use_cuda:\n",
    "    print('Using GPU')\n",
    "    model.cuda()\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWj00WJYZUqL"
   },
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HK3LP6_wRsLH"
   },
   "outputs": [],
   "source": [
    "if load_cropped_data:\n",
    "  test_dir = os.path.join(\"cropped_data\",data_dir + '/test_images/mistery_category')\n",
    "\n",
    "def pil_loader(path):\n",
    "    # open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\n",
    "    with open(path, 'rb') as f:\n",
    "        with Image.open(f) as img:\n",
    "            return img.convert('RGB')\n",
    "\n",
    "\n",
    "output_file = open(outfile, \"w\")\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "for f in tqdm(os.listdir(test_dir)):\n",
    "    if 'jpg' in f:\n",
    "        data = data_transforms_val_test_cropped(pil_loader(test_dir + '/' + f))\n",
    "        data = data.view(1, data.size(0), data.size(1), data.size(2))\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "        output = model(data)\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        output_file.write(\"%s,%d\\n\" % (f[:-4], pred))\n",
    "\n",
    "output_file.close()\n",
    "\n",
    "print(\"Succesfully wrote \" + outfile + ', you can upload this file to the kaggle competition website')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bz73p7UXbkLu"
   },
   "source": [
    "## Majority voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s7F7ar1Ldgaq"
   },
   "source": [
    "This part requires to upload the CSV files manually in the folder given by 'csv_folder' before running it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "chu_390IblCa"
   },
   "outputs": [],
   "source": [
    "csv_folder = 'csv_submissions'\n",
    "majority_outfile = 'results/kaggle_majority_4.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Kh1PjC5cPAQ"
   },
   "outputs": [],
   "source": [
    "output_file = open(majority_outfile, \"w\")\n",
    "output_file.write(\"Id,Category\\n\")\n",
    "\n",
    "csvs = []\n",
    "\n",
    "for file in os.listdir(csv_folder):\n",
    "    if file.endswith(\".csv\"):\n",
    "        csvs.append(pd.read_csv(os.path.join(csv_folder,file)))\n",
    "\n",
    "nb_labels = [0 for i in range(len(csvs))]\n",
    "occurences_max = [0 for i in range(len(csvs))]\n",
    "\n",
    "for f in tqdm(os.listdir(test_dir)):\n",
    "  if 'jpg' in f:\n",
    "    img_name = f[:-4]\n",
    "    labels = []\n",
    "    for csv in csvs:\n",
    "      label = csv[csv['Id'] == img_name].iloc[0]['Category']\n",
    "      labels.append(label)\n",
    "\n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    majority_label = unique[np.argmax(counts)]\n",
    "\n",
    "    nb_labels[len(unique)-1] +=1\n",
    "    occurences_max[max(counts)-1] +=1\n",
    "\n",
    "    output_file.write(\"%s,%d\\n\" % (f[:-4], majority_label))\n",
    "    \n",
    "output_file.close()\n",
    "\n",
    "print(\"Succesfully wrote \" + majority_outfile + ', you can upload this file to the kaggle competition website')\n",
    "print(\"The distribution of the number of labels per image is:\", nb_labels)\n",
    "print(\"The distribution of the number of occurences of the most common label is:\", occurences_max)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "piFGe9UBwkp5"
   ],
   "name": "A3_Jacob_Paul.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
